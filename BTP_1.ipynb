{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8624f1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "096246aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=1234\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "np.random.seed(SEED)\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import os, shutil, scipy.io\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Dense, Activation, add, Dropout, Lambda, Input, average, LSTM\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f608cd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "from numpy import dstack, mean, std, argmax, tensordot, array\n",
    "from numpy.linalg import norm\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from keras.utils import plot_model\n",
    "from scipy.optimize import differential_evolution\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77f6d9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, add, Dropout, Lambda, LSTM, Flatten\n",
    "from keras.layers import Input, average, TimeDistributed, SimpleRNN, LeakyReLU, GlobalAveragePooling1D\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5d2ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "caseNo = 118\n",
    "weight_4_mag = 100\n",
    "weight_4_ang = 180/math.pi\n",
    "\n",
    "psse_data = scipy.io.loadmat('data_for_SE_case'+str(caseNo)+'_for_ML.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "048ea0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39444, 562)\n",
      "(17520, 562)\n"
     ]
    }
   ],
   "source": [
    "data_x = psse_data['Z_measure']\n",
    "data_y = psse_data['Output']\n",
    "print(data_x.shape)\n",
    "data_x=data_x[0:data_y.shape[0], :] # this is because measurement are available for 4 and half years but state estimation is available only for two years for IEEE 118\n",
    "print(data_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c703039",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y[:, 0:caseNo] = weight_4_mag*data_y[:, 0:caseNo]\n",
    "data_y[:, caseNo:] = weight_4_ang*data_y[:, caseNo:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "badabae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train = int(0.6*data_x.shape[0])\n",
    "test_x=data_x[:split_train, :]\n",
    "test_y=data_y[:split_train, :]\n",
    "train_x=data_x[split_train:, :]\n",
    "train_y=data_y[split_train:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aec27552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the hubber loss\n",
    "def huber_loss(y_true, y_pred, clip_delta=1.0):\n",
    "    error = y_true - y_pred\n",
    "    cond  = K.abs(error) < clip_delta\n",
    "    squared_loss = 0.5 * K.square(error)\n",
    "    linear_loss  = clip_delta * (K.abs(error) - 0.5 * clip_delta)\n",
    "    return tf.where(cond, squared_loss, linear_loss)\n",
    "# calculate the hubber loss mean for the compiler\n",
    "def huber_loss_mean(y_true, y_pred):\n",
    "    return K.mean(huber_loss(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3cda2245",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (train_x.shape[1],)\n",
    "num_classes=train_y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94ad49f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn1_psse(input_shape, num_classes, weights=None):\n",
    "    '''\n",
    "    :param input_shape:\n",
    "    :param num_classes:\n",
    "    :param weights: 6 layers\n",
    "    :return: 1 hidden layer NN model with specified training loss\n",
    "    '''\n",
    "    data = Input(shape=input_shape, dtype='float', name='data')\n",
    "    dense1 = Dense(units = input_shape[0], activation='relu',  use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros')(data)\n",
    "    dense2 = Dense(units = input_shape[0], activation='relu',  use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros')(dense1)\n",
    "    dense3 = Dense(units = input_shape[0], activation='relu',  use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros')(dense2)\n",
    "    dense4 = Dense(units = input_shape[0], activation='relu',  use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros')(dense3)\n",
    "    dense5 = Dense(units = input_shape[0], activation='relu',  use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros')(dense4)\n",
    "\n",
    "    dense6 = Dense(units = input_shape[0], activation='relu',  use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros')(dense5)\n",
    "#    dense7 = Dense(units = input_shape[0], activation='relu',  use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros')(dense6)\n",
    "#    dense8 = Dense(units = input_shape[0], activation='relu',  use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros')(dense7)\n",
    "#    dense9 = Dense(units = input_shape[0], activation='relu',  use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros')(dense8)\n",
    "#    dense10 = Dense(units = input_shape[0], activation='relu',  use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros')(dense9)\n",
    "\n",
    "#    drop1 = Dropout(rate=0.5, name='drop1')(dense8)\n",
    "    predictions = Dense(units = num_classes, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros')(dense6)\n",
    "\n",
    "    model = Model(inputs=data, outputs=predictions)\n",
    "    if weights is not None:\n",
    "        model.load_weights(weights)\n",
    "    #sgd = optimizers.adam(lr=0.001)\n",
    "\n",
    "    sgd = optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
    "\n",
    "    model.compile(optimizer=sgd, loss=huber_loss_mean,\n",
    "                  metrics=['mae'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0cb1efa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "110/110 - 5s - loss: 6209.5156 - mae: 6210.0137 - 5s/epoch - 43ms/step\n",
      "Epoch 2/10\n",
      "110/110 - 3s - loss: 6156.8247 - mae: 6157.3232 - 3s/epoch - 26ms/step\n",
      "Epoch 3/10\n",
      "110/110 - 3s - loss: 6156.8169 - mae: 6157.3145 - 3s/epoch - 26ms/step\n",
      "Epoch 4/10\n",
      "110/110 - 3s - loss: 6156.8110 - mae: 6157.3096 - 3s/epoch - 26ms/step\n",
      "Epoch 5/10\n",
      "110/110 - 3s - loss: 6156.8027 - mae: 6157.3003 - 3s/epoch - 26ms/step\n",
      "Epoch 6/10\n",
      "110/110 - 3s - loss: 6156.7944 - mae: 6157.2930 - 3s/epoch - 26ms/step\n",
      "Epoch 7/10\n",
      "110/110 - 3s - loss: 6156.7832 - mae: 6157.2812 - 3s/epoch - 26ms/step\n",
      "Epoch 8/10\n",
      "110/110 - 3s - loss: 6156.7715 - mae: 6157.2695 - 3s/epoch - 27ms/step\n",
      "Epoch 9/10\n",
      "110/110 - 3s - loss: 6156.7534 - mae: 6157.2510 - 3s/epoch - 29ms/step\n",
      "Epoch 10/10\n",
      "110/110 - 3s - loss: 6156.6860 - mae: 6157.1836 - 3s/epoch - 26ms/step\n",
      "> Saved model States_MLP_118/model_1.h5\n",
      "Epoch 1/10\n",
      "110/110 - 4s - loss: 6140.1094 - mae: 6140.6084 - 4s/epoch - 34ms/step\n",
      "Epoch 2/10\n",
      "110/110 - 3s - loss: 6156.8276 - mae: 6157.3252 - 3s/epoch - 25ms/step\n",
      "Epoch 3/10\n",
      "110/110 - 3s - loss: 6156.8188 - mae: 6157.3164 - 3s/epoch - 26ms/step\n",
      "Epoch 4/10\n",
      "110/110 - 3s - loss: 6156.8130 - mae: 6157.3105 - 3s/epoch - 26ms/step\n",
      "Epoch 5/10\n",
      "110/110 - 3s - loss: 6156.8081 - mae: 6157.3062 - 3s/epoch - 26ms/step\n",
      "Epoch 6/10\n",
      "110/110 - 3s - loss: 6156.7998 - mae: 6157.2979 - 3s/epoch - 25ms/step\n",
      "Epoch 7/10\n",
      "110/110 - 3s - loss: 6156.7949 - mae: 6157.2930 - 3s/epoch - 25ms/step\n",
      "Epoch 8/10\n",
      "110/110 - 3s - loss: 6156.7852 - mae: 6157.2842 - 3s/epoch - 25ms/step\n",
      "Epoch 9/10\n",
      "110/110 - 3s - loss: 6156.7812 - mae: 6157.2803 - 3s/epoch - 25ms/step\n",
      "Epoch 10/10\n",
      "110/110 - 3s - loss: 6156.7734 - mae: 6157.2715 - 3s/epoch - 25ms/step\n",
      "> Saved model States_MLP_118/model_2.h5\n",
      "Epoch 1/10\n",
      "110/110 - 4s - loss: 6145.4600 - mae: 6145.9595 - 4s/epoch - 35ms/step\n",
      "Epoch 2/10\n",
      "110/110 - 3s - loss: 6156.8247 - mae: 6157.3218 - 3s/epoch - 25ms/step\n",
      "Epoch 3/10\n",
      "110/110 - 3s - loss: 6156.8179 - mae: 6157.3164 - 3s/epoch - 25ms/step\n",
      "Epoch 4/10\n",
      "110/110 - 3s - loss: 6156.8135 - mae: 6157.3115 - 3s/epoch - 25ms/step\n",
      "Epoch 5/10\n",
      "110/110 - 3s - loss: 6156.8037 - mae: 6157.3027 - 3s/epoch - 25ms/step\n",
      "Epoch 6/10\n",
      "110/110 - 3s - loss: 6156.7983 - mae: 6157.2959 - 3s/epoch - 25ms/step\n",
      "Epoch 7/10\n",
      "110/110 - 3s - loss: 6156.7935 - mae: 6157.2925 - 3s/epoch - 25ms/step\n",
      "Epoch 8/10\n",
      "110/110 - 3s - loss: 6156.7866 - mae: 6157.2842 - 3s/epoch - 25ms/step\n",
      "Epoch 9/10\n",
      "110/110 - 3s - loss: 6156.7769 - mae: 6157.2749 - 3s/epoch - 26ms/step\n",
      "Epoch 10/10\n",
      "110/110 - 3s - loss: 6156.7700 - mae: 6157.2676 - 3s/epoch - 26ms/step\n",
      "> Saved model States_MLP_118/model_3.h5\n",
      "Epoch 1/10\n",
      "110/110 - 4s - loss: 6109.4092 - mae: 6109.9062 - 4s/epoch - 34ms/step\n",
      "Epoch 2/10\n",
      "110/110 - 3s - loss: 6156.4736 - mae: 6156.9702 - 3s/epoch - 25ms/step\n",
      "Epoch 3/10\n",
      "110/110 - 3s - loss: 6600.8843 - mae: 6601.3823 - 3s/epoch - 25ms/step\n",
      "Epoch 4/10\n",
      "110/110 - 3s - loss: 6156.6636 - mae: 6157.1621 - 3s/epoch - 25ms/step\n",
      "Epoch 5/10\n",
      "110/110 - 3s - loss: 6335.9629 - mae: 6336.4624 - 3s/epoch - 25ms/step\n",
      "Epoch 6/10\n",
      "110/110 - 3s - loss: 6156.7979 - mae: 6157.2964 - 3s/epoch - 25ms/step\n",
      "Epoch 7/10\n",
      "110/110 - 3s - loss: 6156.7842 - mae: 6157.2827 - 3s/epoch - 25ms/step\n",
      "Epoch 8/10\n",
      "110/110 - 3s - loss: 6156.7725 - mae: 6157.2705 - 3s/epoch - 25ms/step\n",
      "Epoch 9/10\n",
      "110/110 - 3s - loss: 6156.7573 - mae: 6157.2559 - 3s/epoch - 25ms/step\n",
      "Epoch 10/10\n",
      "110/110 - 3s - loss: 6156.7354 - mae: 6157.2324 - 3s/epoch - 25ms/step\n",
      "> Saved model States_MLP_118/model_4.h5\n",
      "Epoch 1/10\n",
      "110/110 - 4s - loss: 6133.2925 - mae: 6133.7915 - 4s/epoch - 33ms/step\n",
      "Epoch 2/10\n",
      "110/110 - 3s - loss: 6156.8271 - mae: 6157.3242 - 3s/epoch - 25ms/step\n",
      "Epoch 3/10\n",
      "110/110 - 3s - loss: 6156.8198 - mae: 6157.3149 - 3s/epoch - 25ms/step\n",
      "Epoch 4/10\n",
      "110/110 - 3s - loss: 6156.8130 - mae: 6157.3110 - 3s/epoch - 26ms/step\n",
      "Epoch 5/10\n",
      "110/110 - 3s - loss: 6156.8071 - mae: 6157.3037 - 3s/epoch - 25ms/step\n",
      "Epoch 6/10\n",
      "110/110 - 3s - loss: 6156.8013 - mae: 6157.3003 - 3s/epoch - 25ms/step\n",
      "Epoch 7/10\n",
      "110/110 - 3s - loss: 6156.7949 - mae: 6157.2939 - 3s/epoch - 25ms/step\n",
      "Epoch 8/10\n",
      "110/110 - 3s - loss: 6156.7876 - mae: 6157.2866 - 3s/epoch - 25ms/step\n",
      "Epoch 9/10\n",
      "110/110 - 3s - loss: 6156.7783 - mae: 6157.2769 - 3s/epoch - 26ms/step\n",
      "Epoch 10/10\n",
      "110/110 - 3s - loss: 6156.7725 - mae: 6157.2700 - 3s/epoch - 25ms/step\n",
      "> Saved model States_MLP_118/model_5.h5\n",
      "Epoch 1/10\n",
      "110/110 - 4s - loss: 6271.7378 - mae: 6272.2363 - 4s/epoch - 33ms/step\n",
      "Epoch 2/10\n",
      "110/110 - 3s - loss: 6156.8286 - mae: 6157.3276 - 3s/epoch - 25ms/step\n",
      "Epoch 3/10\n",
      "110/110 - 3s - loss: 6156.8203 - mae: 6157.3169 - 3s/epoch - 25ms/step\n",
      "Epoch 4/10\n",
      "110/110 - 3s - loss: 6156.8130 - mae: 6157.3105 - 3s/epoch - 25ms/step\n",
      "Epoch 5/10\n",
      "110/110 - 3s - loss: 6156.8062 - mae: 6157.3032 - 3s/epoch - 25ms/step\n",
      "Epoch 6/10\n",
      "110/110 - 3s - loss: 6156.7983 - mae: 6157.2964 - 3s/epoch - 25ms/step\n",
      "Epoch 7/10\n",
      "110/110 - 3s - loss: 6156.7930 - mae: 6157.2900 - 3s/epoch - 25ms/step\n",
      "Epoch 8/10\n",
      "110/110 - 3s - loss: 6156.7847 - mae: 6157.2827 - 3s/epoch - 25ms/step\n",
      "Epoch 9/10\n",
      "110/110 - 3s - loss: 6156.7749 - mae: 6157.2734 - 3s/epoch - 25ms/step\n",
      "Epoch 10/10\n",
      "110/110 - 3s - loss: 6156.7661 - mae: 6157.2637 - 3s/epoch - 25ms/step\n",
      "> Saved model States_MLP_118/model_6.h5\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 200\n",
    "# # create directory for models\n",
    "#makedirs('States_MLP_118') # For CNN\n",
    "\n",
    "\n",
    "def fit_model_DNN(train_x, train_y, input_shape, num_classes):\n",
    "    psse_model = nn1_psse(input_shape, num_classes, weights=None) # For DNN\n",
    "    psse_model.fit(train_x, train_y, epochs=200, batch_size=64, verbose=2)\n",
    "    return psse_model\n",
    "\n",
    "\n",
    "# # fit and save model models to use later for ensembling\n",
    "n_members=6\n",
    "for i in range(n_members):\n",
    "#     # fit model\n",
    "     model = fit_model_DNN(train_x, train_y, input_shape, num_classes)\n",
    "#    # save model\n",
    "     filename = 'States_MLP_118/model_' + str(i + 1) + '.h5'  # for DNN\n",
    "     model.save(filename)\n",
    "     print('> Saved model %s' % filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "875eb052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_models(n_models):\n",
    "    all_models=list()\n",
    "    for i in range(n_models):\n",
    "        # define filename for this ensemble\n",
    "        filename = 'States_MLP_'+str(caseNo)+'/model_' + str(i + 1) + '.h5'  # for Combined\n",
    "        # load model from file\n",
    "        #model=load_model(filename) # use this for MLP\n",
    "        model=load_model(filename, custom_objects={'huber_loss_mean':huber_loss_mean})\n",
    "        # add to list of members\n",
    "        all_models.append(model)\n",
    "        print('>loaded %s' % filename)\n",
    "    return all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2fc74d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded States_MLP_118/model_1.h5\n",
      ">loaded States_MLP_118/model_2.h5\n",
      ">loaded States_MLP_118/model_3.h5\n",
      ">loaded States_MLP_118/model_4.h5\n",
      ">loaded States_MLP_118/model_5.h5\n",
      ">loaded States_MLP_118/model_6.h5\n",
      "Loaded 6 models\n"
     ]
    }
   ],
   "source": [
    "n_members=6\n",
    "members=load_all_models(n_members)\n",
    "print('Loaded %d models' %len(members))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc83a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train = int(0.6*test_x.shape[0])\n",
    "mtrain_x=test_x[:split_train, :]\n",
    "mtrain_y=test_y[:split_train, :]\n",
    "test_x=test_x[split_train:, :]\n",
    "test_y=test_y[split_train:, :]\n",
    "\n",
    "#data_new=scipy.io.loadmat('States_onli_SE_case'+str(caseNo)+'_for_ML.mat')\n",
    "data_new=scipy.io.loadmat('States_onli_SE_case'+str(caseNo)+'_for_ML_Non_Gaussian.mat')\n",
    "data_testy=data_new['Output']\n",
    "data_testx=data_new['Z_measure']\n",
    "\n",
    "data_testy[:, 0:caseNo] = weight_4_mag*data_testy[:, 0:caseNo]\n",
    "data_testy[:, caseNo:] = weight_4_ang*data_testy[:, caseNo:]\n",
    "\n",
    "test_x=data_testx[0:data_testy.shape[0], :]\n",
    "test_y=data_testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a7b4982f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 [==============================] - 2s 6ms/step\n",
      "Per iteration time: 0.204935\n",
      "Model Test data RMSEv: 9685.0404\n",
      "Model Test data MAEv: 9679.2712\n",
      "Model Test data RMSEa: 2861.8089\n",
      "Model Test data MAEa: 2615.5814\n",
      "329/329 [==============================] - 2s 6ms/step\n",
      "Per iteration time: 0.206695\n",
      "Model Test data RMSEv: 9685.3346\n",
      "Model Test data MAEv: 9679.5647\n",
      "Model Test data RMSEa: 2861.9339\n",
      "Model Test data MAEa: 2615.7096\n",
      "329/329 [==============================] - 2s 6ms/step\n",
      "Per iteration time: 0.209909\n",
      "Model Test data RMSEv: 9685.3297\n",
      "Model Test data MAEv: 9679.5598\n",
      "Model Test data RMSEa: 2861.9323\n",
      "Model Test data MAEa: 2615.7072\n",
      "329/329 [==============================] - 2s 6ms/step\n",
      "Per iteration time: 0.208452\n",
      "Model Test data RMSEv: 9685.2559\n",
      "Model Test data MAEv: 9679.4859\n",
      "Model Test data RMSEa: 2861.9137\n",
      "Model Test data MAEa: 2615.6839\n",
      "329/329 [==============================] - 2s 6ms/step\n",
      "Per iteration time: 0.207111\n",
      "Model Test data RMSEv: 9685.3331\n",
      "Model Test data MAEv: 9679.5633\n",
      "Model Test data RMSEa: 2861.9343\n",
      "Model Test data MAEa: 2615.7087\n",
      "329/329 [==============================] - 2s 6ms/step\n",
      "Per iteration time: 0.213676\n",
      "Model Test data RMSEv: 9685.3225\n",
      "Model Test data MAEv: 9679.5524\n",
      "Model Test data RMSEa: 2861.9267\n",
      "Model Test data MAEa: 2615.7015\n",
      "RMSE to win min model for voltage is : 9685.0404\n",
      "MAE to win min model for voltage is : 9679.2712\n",
      "RMSE to win min model for phase is : 2861.8089\n",
      "MAE to win min model for phase is : 2615.5814\n"
     ]
    }
   ],
   "source": [
    "vrmse=100000\n",
    "for model in members:\n",
    "    start = timeit.default_timer()\n",
    "    yhat = model.predict(test_x)\n",
    "    stop = timeit.default_timer()\n",
    "    # print('Time: %f' % (stop - start))\n",
    "    print('Per iteration time: %f' % ((stop - start) / test_x.shape[0] * 1000))\n",
    "\n",
    "\n",
    "    RMSEv = np.sqrt(mean_squared_error(yhat[:, 0:caseNo], test_y[:, 0:caseNo]))\n",
    "    print('Model Test data RMSEv: %.4f' % RMSEv)\n",
    "    MAEv = mean_absolute_error(yhat[:, 0:caseNo], test_y[:, 0:caseNo])\n",
    "    print('Model Test data MAEv: %.4f' % MAEv)\n",
    "\n",
    "    RMSEa = np.sqrt(mean_squared_error(yhat[:, caseNo:], test_y[:, caseNo:]))\n",
    "    print('Model Test data RMSEa: %.4f' % RMSEa)\n",
    "    MAEa = mean_absolute_error(yhat[:, caseNo:], test_y[:, caseNo:])\n",
    "    print('Model Test data MAEa: %.4f' % MAEa)\n",
    "\n",
    "    if vrmse > RMSEv:\n",
    "        yhat_save = yhat\n",
    "        vrmse = RMSEv\n",
    "        vmae = MAEv\n",
    "        armse = RMSEa\n",
    "        amae = MAEa\n",
    "        \n",
    "\n",
    "print('RMSE to win min model for voltage is : %.4f' % vrmse)\n",
    "print('MAE to win min model for voltage is : %.4f' % vmae)\n",
    "print('RMSE to win min model for phase is : %.4f' % armse)\n",
    "print('MAE to win min model for phase is : %.4f' % amae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
